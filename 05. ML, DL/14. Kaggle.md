# 머신러닝, 딥러닝

## - Kaggle-Titanic

머신러닝에서 가장 유명한 커뮤니티인 Kaggle을 이용해보자.

안에서 가입을 하고, 검색창에 [titanic](https://www.kaggle.com/c/titanic)을 쳐서 들어가보자.

Overivew는 이 data에 대한 설명, Data는 train.csv와 test.csv를 제공한다.

train.csv데이터에는 입력값과 생존여부(결과값)이 다 들어있고, test.csv데이터에는 입력값만 들어있다. 그리고 결과값은 안들어있고, 우리가 만들어서 채운 후 케글에 제출하면 정답이 채점된다. gender_submission이 제출형식이다. 다운받아서 늘 넣는 주피터노트북 데이터 경로에 넣어보자.

```python
import numpy as np
import pandas as pd
import

data = read_csv('./data/titanic/train.csv')

```

- PassendgerId : 승객번호는 생존여부와 상관 없을 것 같다.
- Pclass: 탑승 클래스는 생존여부와 상관이 있을 <u>것 같다</u>. 이건 우리의 추측, 상식이다. 그럼 얼마나 많은 연관과, 진짜 연관이 있는지는 데이터 분석을 해보고 가중치를 얼마나 줄지 생각해봐야 한다.
- Name: 상관없는 듯 보이지만, 함부로 날리기가 아쉽다. 잘보면 age에서 NaN이 들어가있는 사람이 있는데, 이전처럼 NaN데이터를 다날리기엔 데이터가 너무 적어 문제가 생긴다. 그래서 NaN으로 대체하고 싶은데, 이 값을 추측하고 싶다. 보통 평균으로 채운다 하여, 여자나이의 평균으로 채울 수 있지만 이름에 Miss가 들어있으면 결혼을 안한 여성일테니 Miss의 이름이 붙은 사람 나이의 평균으로 채우는게 조금 더 정확할 수 있다. 이런식으로 데이터가 중요할 수도 있다. 단순한 이름만 적혀있었다면 데이터를 날려도 됐지만 정보가 포함되어있는 데이터이므로 날리기 아쉬운 데이터다.
- Sex: 성별은 생존의 여부에 지대한 영향을 끼친다. 여자를 많이 살렸을 것이고, 직접 데이터를 확인해보면 있다.
- Age: 가족이 탔다면 애들부터 살렸을 것 같으므로, 영향이 있을 것이다.
- SipSp,Parch: 가족이 있다면 영향을 끼쳤을 거 같다. 근데 이 두데이터는 둘다 가족의 데이터이므로 이러한 비슷한 데이터는 합치는게 좋다. 가중치를 더해줄뿐이며 오버피팅이 일어날 가능성도 있다. 이렇다는게 맞다는 것이아니라 이렇게할 수 있다는 것이다.
- Ticket: 티켓번호가 영향을 끼칠까? 이건 생각해봐야한다. 티켓번호에 배의 위치가 있다면 영향을 끼칠 수 있고, 아무런 정보가 없는 랜덤번호라면 영향을 끼치지 않을 수 있다.
- Fare: 요금과 Class가 비슷할 거 같다. 여기서는 요금을 무시해보자.
- Cabin: 객실위치, 정보가 분명이 도움이 될거같은데, NaN이 너무 많아서 버려야할 것 같다.
- Embarked: 승선위치가 영향을 끼칠까? 겉보기엔 없어보이지만 데이터를 분석해보면 있다. 어느지역은 잘사는 지역, 어느지역은 못사는지역이라고 추측된다.




```python
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split

df = pd.read_csv('./data/titanic/train.csv')

train_df = df.drop(['PassengerId', 'Fare', 'Cabin', 'Ticket'], axis=1)
sex_mapping = {'male':0, 'female':1}
# 매핑 룰
train_df['Sex'] = train_df['Sex'].map(sex_mapping)
# 매핑
train_df['Family'] = train_df['SibSp'] + train_df['Parch']
train_df = train_df.drop(['SibSp', 'Parch'], axis=1)

embarked_mapping = {'S': 0, 'C': 1, 'Q': 2}
train_df['Embarked'] = train_df['Embarked'].map(embarked_mapping)
# train_df['Age'] = train_df['Age'].fillna(train_df['Age'].mean())
# 이런식으로 채울 수 있다.
# print(train_df.loc[train_df['Age']<30,'Age'])
train_df.Name = train_df.Name.str.extract(' ([A-Za-z]+)\.', expand=False)
# 이름 변경
# display(pd.crosstab(train_df['Name'], train_df['Age'].isnull()))
# 얼마나 Nan인지 확인

# print(train_df.Name.unique())
median_Mr = train_df[['Name','Age']].loc[(train_df['Name']=='Mr') & train_df['Age'].notna(),'Age'].median()
median_Dr = train_df[['Name','Age']].loc[(train_df['Name']=='Dr') & train_df['Age'].notna(),'Age'].median()
median_Master = train_df[['Name','Age']].loc[(train_df['Name']=='Master') & train_df['Age'].notna(),'Age'].median()
median_Miss = train_df[['Name','Age']].loc[(train_df['Name']=='Miss') & train_df['Age'].notna(),'Age'].median()
median_Mrs = train_df[['Name','Age']].loc[(train_df['Name']=='Mrs') & train_df['Age'].notna(),'Age'].median()

train_df.loc[train_df['Name']=='Mr', 'Age'] = train_df.loc[train_df['Name']=='Mr', 'Age'].fillna(median_Mr)
train_df.loc[train_df['Name']=='Dr', 'Age'] = train_df.loc[train_df['Name']=='Dr', 'Age'].fillna(median_Dr)
train_df.loc[train_df['Name']=='Master', 'Age'] = train_df.loc[train_df['Name']=='Master', 'Age'].fillna(median_Master)
train_df.loc[train_df['Name']=='Miss', 'Age'] = train_df.loc[train_df['Name']=='Miss', 'Age'].fillna(median_Miss)
train_df.loc[train_df['Name']=='Mrs', 'Age'] = train_df.loc[train_df['Name']=='Mrs', 'Age'].fillna(median_Mrs)
# age값 대체.

train_df = train_df.drop('Name', axis=1)
# Name사용했으니 제외.

train_df['Embarked'] = train_df['Embarked'].fillna(train_df['Embarked'].mode()[0])
# 승선지 제일 많은곳으로 대체


train_df.loc[train_df['Age'] < 21,'Age'] = 0
train_df.loc[(train_df['Age'] >= 21) & (train_df['Age'] < 30),'Age'] = 1
train_df.loc[(train_df['Age'] >= 30) & (train_df['Age'] < 35),'Age'] = 2
train_df.loc[train_df['Age'] >= 35,'Age'] = 3
# display(train_df)
# 나이 정제완료
train_df.loc[train_df['Family'] >= 1,'Family'] = 1
# 가족도 정리

# display(train_df)



x_data = train_df.loc[:,'Pclass':'Family'].values
t_data = train_df.loc[:,'Survived'].values.reshape(-1,1)


train_x, val_x, train_t, val_t = \
train_test_split(x_data,
                 t_data,
                 test_size=0.2,
                 stratify=t_data,
                 random_state=2)


display(train_t)

# Tensorflow 구현(v1.15)

X = tf.placeholder(shape=[None,5], dtype=tf.float32)
T = tf.placeholder(shape=[None,1], dtype=tf.float32)

W = tf.Variable(tf.random.normal([5,1]))
b = tf.Variable(tf.random.normal([1]))

# Hypothesis
logit = tf.matmul(X,W) + b
H = tf.sigmoid(logit)

# Loss function
loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,
                                                              labels=T))
# train
train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)

# session & 초기화
sess = tf.Session()
sess.run(tf.global_variables_initializer())

for step in range(300000):
    tmp, loss_val = sess.run([train,loss], 
                         feed_dict={X:train_x, T:train_t.reshape(-1,1)})
    if not step % 30000:
        print('loss: {}'.format(loss_val))
        
-------------------------------------------------------------------------------
loss: 2.9629549980163574
loss: 0.5663396716117859
loss: 0.531190037727356
loss: 0.5076343417167664
loss: 0.49160754680633545
loss: 0.4804692566394806
loss: 0.47255784273147583
loss: 0.466796875
loss: 0.46252888441085815
loss: 0.4592961370944977
```

예측

```python
predict = tf.cast(H > 0.5, dtype=tf.float32)
correct = tf.equal(predict, T)
acc = tf.reduce_mean(tf.cast(correct,tf.float32))
# 얘도 node임. 실행시켜야함.

acc_val = sess.run(acc, feed_dict={X:val_x, T:val_t.reshape(-1,1)})
print(acc_val)
--------------------------------------------------------------------------------
0.78778095
```

케글에 제출하는 코드까지 마저 작성해보자.

```python
df = pd.read_csv('./data/titanic/test.csv')
submission = pd.read_csv('./data/titanic/submission.csv')
test_df = df.drop(['PassengerId', 'Fare', 'Cabin', 'Ticket'], axis=1)
sex_mapping = {'male':0, 'female':1}
# 매핑 룰
test_df['Sex'] = test_df['Sex'].map(sex_mapping)
# 매핑
test_df['Family'] = test_df['SibSp'] + test_df['Parch']
test_df = test_df.drop(['SibSp', 'Parch'], axis=1)

embarked_mapping = {'S': 0, 'C': 1, 'Q': 2}
test_df['Embarked'] = test_df['Embarked'].map(embarked_mapping)
# train_df['Age'] = train_df['Age'].fillna(train_df['Age'].mean())
# 이런식으로 채울 수 있다.
# print(train_df.loc[train_df['Age']<30,'Age'])
test_df.Name = test_df.Name.str.extract(' ([A-Za-z]+)\.', expand=False)
# 이름 변경
# display(pd.crosstab(train_df['Name'], train_df['Age'].isnull()))
# 얼마나 Nan인지 확인

# print(train_df.Name.unique())
median_Mr = test_df[['Name','Age']].loc[(test_df['Name']=='Mr') & test_df['Age'].notna(),'Age'].median()
median_Dr = test_df[['Name','Age']].loc[(test_df['Name']=='Dr') & test_df['Age'].notna(),'Age'].median()
median_Master = test_df[['Name','Age']].loc[(test_df['Name']=='Master') & test_df['Age'].notna(),'Age'].median()
median_Miss = test_df[['Name','Age']].loc[(test_df['Name']=='Miss') & test_df['Age'].notna(),'Age'].median()
median_Mrs = test_df[['Name','Age']].loc[(test_df['Name']=='Mrs') & test_df['Age'].notna(),'Age'].median()

test_df.loc[test_df['Name']=='Mr', 'Age'] = test_df.loc[test_df['Name']=='Mr', 'Age'].fillna(median_Mr)
test_df.loc[test_df['Name']=='Dr', 'Age'] = test_df.loc[test_df['Name']=='Dr', 'Age'].fillna(median_Dr)
test_df.loc[test_df['Name']=='Master', 'Age'] = test_df.loc[test_df['Name']=='Master', 'Age'].fillna(median_Master)
test_df.loc[test_df['Name']=='Miss', 'Age'] = test_df.loc[test_df['Name']=='Miss', 'Age'].fillna(median_Miss)
test_df.loc[test_df['Name']=='Mrs', 'Age'] = test_df.loc[test_df['Name']=='Mrs', 'Age'].fillna(median_Mrs)
# age값 대체.

test_df = test_df.drop('Name', axis=1)
# Name사용했으니 제외.

test_df['Embarked'] = test_df['Embarked'].fillna(test_df['Embarked'].mode()[0])
# 승선지 제일 많은곳으로 대체


test_df.loc[test_df['Age'] < 21,'Age'] = 0
test_df.loc[(test_df['Age'] >= 21) & (test_df['Age'] < 30),'Age'] = 1
test_df.loc[(test_df['Age'] >= 30) & (test_df['Age'] < 35),'Age'] = 2
test_df.loc[test_df['Age'] >= 35,'Age'] = 3
# display(train_df)
# 나이 정제완료
test_df.loc[test_df['Family'] >= 1,'Family'] = 1
# 가족도 정리

# display(train_df)

x_test_data = test_df.loc[:,'Pclass':'Family'].values


display(x_test_data)
predict = sess.run(tf.cast(H>0.5, dtype=tf.float32), feed_dict={X:x_test_data})
submission['Survived'] = predict.astype(int)
submission.to_csv('./data/titanic/submission.csv', index=False)
```

정확도는 77%로 나왔다.