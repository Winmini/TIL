# 머신러닝, 딥러닝

## - Sklearn



저번에는 python으로 머신러닝을 다 구현했었다. 이 방법은 엄청나게 어려운 것은 아니지만, 어려웠다. 그래서 좀 쉬운 library를 이용해서 해보자. 그 중 가장 대표적인게 Sklearn이다.

싸이킷런을 이용하는 것은 좋지만 이것만을 알고서는 실제 문제들을 해결해나갈 수 없다. 싸이킷런은 주로 정답용으로 많이 이용한다.

anaconda를 이용해 data_env가상환경으로 이동하여 `pip install sklearn`으로 설치부터 해주자.

바로 실습으로 넘어가보자

---

### 예제

```python
import numpy as np
from sklearn import linear_model
# linear model부터 사용해보자.

x_data = np.array([1,2,3,4,5]).reshape(-1, 1)
t_data = np.array([3,5,7,9,11]).reshape(-1, 1)

model = linear_model.LinearRegression()
# 모델객체는 줬지만 아직 학습은 안시켰다.

model.fit(x_data, t_data)
# 알아서 학습까지 완료해서 모델 완성

# 학습된 weight과 bias를 확인해보자.
print('weight: {}, bias: {}'.format(model.coef_, model.intercept_))

print(model.predict([[20]]))
# 예측값
------------------------------------------------------------------------------
weight: [[2.]], bias: [1.]
[[41.]]
```

---

### 실습

이제 싸이킷런과 직접 짜는 코딩을 비교하기 위해 오존의 실측데이터가지고 직접 확인해보자.

오존.csv를 받아서, 주피터노트북관리하는 폴더내에 넣어주자.

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def numerical_derivative(f, x):
    # f: 미분을 하려고하는 함수
    # x: 모든 독립변수의 값을 포함하고 있는 ndarray
    delta_x = 1e-4
    derivative_x = np.zeros_like(x)
    
    it = np.nditer(x, flags=['multi_index'])
    
    while not it.finished:
        idx = it.multi_index
        tmp = x[idx]
        x[idx] = tmp + delta_x
        fx_plus_deltax = f(x)
        
        x[idx] = tmp - delta_x
        fx_minus_deltax = f(x)
        
        derivative_x[idx] = (fx_plus_deltax - fx_minus_deltax) / (2 * delta_x)
        x[idx] = tmp
        
        it.iternext()
        
    return derivative_x
  
# Raw Data Loading
df = pd.read_csv('./data/ozone/ozone.csv', sep=',')

display(df.head())
'''
data를 분석하기위해 파악부터,,
태양의 세기, 온도, 바람에 따른 오존량을 측정한 데이터
세기, 온도, 바람이 입력이 되는 것이고, 오존량이 label이다.
'''

# Simple Linear Regression 예제를 위해 x데이터를 온도만 사용해보자.
training_data_set = df[['Temp', 'Ozone']]

# 결치값이 존재하므로 이거 추려야한다. 지금은 일단 결치값을 삭제하자
training_data_set = training_data_set.dropna(how='any')
# 153행 => 116행, 전체 데이터에 비해 너무 많이 줄어서 여기선 좋은 방법이 아니다.

# 이상치
plt.scatter(training_data_set['Temp'], training_data_set['Ozone'])
'''
산점도를 그려 확인해보자.
확인했을 때 튀는 데이터가 있더라도 그 기준은 우리가 정하는게 아니다.
domain 전문가에게 이 데이터가 이상치인지 직접 확인을 해야한다.
만약 나타날 수 있는 값이라면 중요한 데이터이므로 머신러닝으로 포함시켜야 한다.
이상치가 있는 것을 scatter로 확인했으면 일단 넘어가자....
'''

x_data = training_data_set['Temp'].values.reshape(-1, 1)
t_data = training_data_set['Ozone'].values.reshape(-1, 1)
# 데이터셋 준비

# weight와 bias 정의
w = np.random.rand(1,1)
b = np.random.rand(1)

def predict(x):
	return np.dot(x, W) + b

def loss_func(input_value):
    input_w = input_value[0].reshape(-1,1)
    input_b = input_value[1]

    # 평균제곱오차를 이용한 loss값 계산
    y = np.dot(x_data, input_w) + input_b
    return np.power((t_data - y), 2).mean()

learning_rate = 1e-4

for i in range(300000):
    input_param = np.concatenate((w.ravel(),b), axis=0)
    w = w - learning_rate * numerical_derivative(loss_func, input_param)
    if step % 30000 == 0:
        print('W : {}, b : {}'.format(W,b))  
 

------------------------------------------------------------------------------
	Ozone	Solar.R	Wind	Temp	Month	Day
0	41.0	190.0	7.4	67	5	1
1	36.0	118.0	8.0	72	5	2
2	12.0	149.0	12.6	74	5	3
3	18.0	313.0	11.5	62	5	4
4	NaN	NaN	14.3	56	5	5

W : [[0.56149874]], b : [0.57933292]
W : [[0.71660646]], b : [-11.7124863]
W : [[0.85921057]], b : [-22.98048907]
W : [[0.98993688]], b : [-33.30995646]
W : [[1.10977473]], b : [-42.77906104]
W : [[1.21963103]], b : [-51.4594642]
W : [[1.32033717]], b : [-59.41685853]
W : [[1.41265529]], b : [-66.71146494]
W : [[1.49728405]], b : [-73.39848842]
W : [[1.57486389]], b : [-79.5285358]
```

우리가 구한 모델로 예측을 해보면

```python
print(predict([[62]]))
------------------------------------------------------------------------------
[[16.90292092]]
```

실제로는 18도로 어느정도 잘 맞는 것 같다. 하지만 이게 머신러닝이 제대로 진행되었다기엔 무리가 있다. 머신러닝엔 정답이 없으며, 게런티도 없다.

이제 사이킷런으로 한번 코드를 실행시켜보자.

```python
from sklearn import linear_model

model = linear_model.LinearRegression()
model.fit(x_data, t_data)
print('W: {}, b: {}'.format(model.coef_, model.intercept_))
print(model.predict([[62]]))
------------------------------------------------------------------------------
W: [[2.4287033]], b: [-146.99549097]
[[3.58411393]]
```

사이킷런으로 예측한 값은 3.58이다. 누가 더 잘맞는 결과일까?



당연히 사이킷런이다. 우리가 이렇게 대충만든 결과로 사이킷런과 비교될 수 없다.

그래프로 확인해보자

```python
plt.scatter(x_data, t_data)
plt.plot(x_data, x_data*W + b, color='r')
plt.plot(x_data, x_data*model.coef_ + model.intercept_, color='g')
plt.show
```

![비교](./jpgfile/비교그래프.png)

초록선이 사이킷런, 빨간선이 내가 해본 결과이다.

왜 이런 차이가 났을까?

일단 우리가 지금까지 했던 방법중에 여러 문제가 있다. 우선 학습이 제대로 진행되고 있는게 파악을 하지 않았다. w값이 변동되는 것을 계속 봤는데 뭐가 문제일까?

w값은 사실 중요하지 않다. 손실함수 값을 봐야 한다. w값이 변하면서 손실함수값이 더 커질 수 도있는 것이다. 따라서 다음과 같이 수정해야 한다.

```python
for i in range(300000):
    input_param = np.concatenate((w.ravel(),b), axis=0)
    w = w - learning_rate * numerical_derivative(loss_func, input_param)
    if i % 30000 == 0:
        print('W : {}, b : {}, loss :{}'.format(W,b,loss_func(input_param)))
------------------------------------------------------------------------------
W : [[0.47973442]], b : [0.96293395], loss :1545.2174690067009
W : [[0.7121448]], b : [-11.35994406], loss :819.3687779396851
W : [[0.85512053]], b : [-22.65731081], loss :776.7914658052483
W : [[0.98618751]], b : [-33.01369639], loss :741.0114762941511
W : [[1.10633765]], b : [-42.50747708], loss :710.9436400397801
W : [[1.21648024]], b : [-51.21050104], loss :685.6760312642257
W : [[1.31744882]], b : [-59.18863203], loss :664.4423100268665
W : [[1.41000751]], b : [-66.5022479], loss :646.5984799442307
W : [[1.4948568]], b : [-73.2066975], loss :631.6033564583976
W : [[1.57263882]], b : [-79.35271955], loss :619.0021532797421
```

loss를 확인해보면 0에 가까워야하는데 터무늬없이 크다. 계속 줄어들고 있으므로 우선 학습량이 부족했을 수 있다.

사실 로직에는 크게 문제가 없다.

데이터 전처리 문제가 크다. 이상치(outlier)를 우리가 일단 무시했다. 우리가 했던 모델은 평균으로의 회귀인데, 이런 이상치가 평균과 표준편차에 큰 영향을 끼친다. 따라서 반드시 처리를 해줘야하는 값들이다.

참고로 결측치도 우리가 그냥 날렸기 때문에 <u>문제가 되긴 하는 작업</u>이였지만 사이킷런과 직접한 모델에 동일한 데이터를 넣었기에 여기서 차이는 아닐 것이다.



이상치는 2가지가 있다. 우리가 넣는 x값인 독립변수쪽에서의 이상치와 나오는 결과의 즉 종속변수의 y값중 이상치가 있다. 독립변수쪽 이상치를 지대점(많지 않음), 그리고 종속변수의 이상치를 outlier라고 한다.

![설명](./jpgfile/설명.png)

그럼 반드시 처리해야하는 이 이상치의 기준이 뭘까? 이 이상치를 검출하는 방법은 한두개가 아니다.

- Variance
- Likelihood
- NN
- Density

등 수학적으로 여러 기법들이 있다. 그리고 앞서 말했듯 처리하기전에 먼저 전문가에게 가능한 값인지는 확인하고 해야한다.



이상치 검출에서 가장 많이 사용하는 2가지를 소개하겠다.

- 사분위를 이용한 **Tukey Fence**
- 정규분포와 표준편차를 이용한 **z-score**

---

### Tukey Fence

matplotlib같은 visualization module들은 보통 Boxplot기능을 제공한다.

boxplot은 다음과 같다.

![boxplot](./jpgfile/boxplot.png)

IQR: 1사분위와 3사분위 사이의 <u>범위</u>를 지칭

IQR value: 3사분위값 - 1사분위 값

만약 1사분위 값 - (IQR value * 1.5) 보다 낮은 값이 있거나, 3사분위 값 + (IQR value * 1.5) 이 값보다 더 큰 값이 있다면 이 값을 **이상치**로 한다.

실습으로 확인해보자.

```python
import numpy as np
import matplotlib.pyplot as plt

data = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,22.1])

fig = plt.figure()
# 새로운 figure(도화지) 생성

fig_1 = fig.add_subplot(1,2, 1)
# 1행, 2열로 생성함 (그림을 2장 그림) 그 다음 1은 1번 위치
fig_2 = fig.add_subplot(1,2, 2)
# 2번그림

fig_1.set_title('Original Data Boxplot')
fig_1.boxplot(data)

fig.tight_layout()
# 위치 예쁘게 조절

plt.show()
```

![그래프](./jpgfile/box실습.png)

이렇게 나옴을 확인할 수 있다. 동그라미가 생겼으면 그 값은 무조건 이상치이다.

boxplot을 확인했더니 이상치가 있다! 그러면 제거해야겠다.

numpy로 사분위수를 구하고 코드로 직접 실행해보자. `percentile()` 함수를 이용하면 된다.

```python
print(np.percentile(data,25)) # 4.5
print(np.percentile(data,50)) # 8.0
print(np.median(data)) # 8.0
# 보통 중위값은 median을 쓴다.
print(np.percentile(data,75)) # 11.5

IQR_value = np.percentile(data,75) - np.percentile(data,25) # 7.0

upper_bound = np.percentile(data,75) + IQR_value * 1.5 # 22.0
# 이 값보다 크면 이상치이다.
lower_bound = np.percentile(data,25) - IQR_value * 1.5 # -6.0
# 이 값보다 작으면 이상치이다.

print(data[(data > upper_bound)|(data < lower_bound)])
# boolean indexing

result_data = data[(data <= upper_bound) & (data >= lower_bound)]
# 이상치를 정제하고난 데이터
print(result_data)
------------------------------------------------------------------------------
[22.1]
[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14.]
```

이제 마지막으로 그려보자.

```python
fig_2.set_title(Remove Outlier Data Boxplot)
fig_2.boxplot(result_data)
fig.tight_layout()
plt.show()
```

![정제](./jpgfile/정제된 box.png)

---

### Z Score

이상치를 처리하는 또 다른 방법으로 정규분포와 표준편차를 이용해보자.

전체 데이터에 대해서 상위 97.7% 이상과 하위 2.3% 이하를 이상치로 잡아보자.

![ZSCORE](./jpgfile/ZSCORE.png)

저 빨간 범위 밖은 모두 이상치로 처리하는 것이다. 물론 이 몇 % 를 설정하는지는 내 마음이다. 84.1%로 해도되고, 99.9%로 해도된다. 그렇게 정하면 그에 해당하는 Z Score값이 정해져있다.

직접 코드로 실행해보자.

```python
from scipy import stats

data = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,22.1])
zscore_threshold = 2.0 # 97.7%에 해당하는 zscore값, 보통 2.0을 많이 사용

print(stats.zscore(data))
# zscore값으로 변환

outlier = data[np.abs(stats.zscore(data)) > zscore_threshold]
# boolean indexing
print(outlier) # 22.1

print(data[np.isin(data, outlier, invert=True)])
# data 안에 outlier가 있니? invert에 따라 결과가 뒤집혀서 나온다.
# boolean indexing이 나온다.
# 그것을 이용해 data를 정제함
------------------------------------------------------------------------------
[-1.40160702 -1.21405925 -1.02651147 -0.8389637  -0.65141593 -0.46386816
 -0.27632038 -0.08877261  0.09877516  0.28632293  0.4738707   0.66141848
  0.84896625  1.03651402  2.55565098]
[22.1]
[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14.]
```

함수를 이용해서 zscore가 좀더 간편하다.

가장~ 일반적인 것은 Tukey fance긴 하다.



---

### 실습

온도와 오존량의 machine learning 문제에서 이상치를 제거하고, python과 sklearn의 결과를 비교하고 확인해보자.

막상 해보면 또 loss값이 역시 600근처에서 내려가지 않고, 생각보다 드라마틱한 변화가 안보인다.

더 큰 문제가 남아있기 때문이다. => 데이터 정규화처리이다.

나중에 데이터 처리를 하기위해서는 이제 이상치처리, 결측치처리, 정규화처리는 꼭 진행되어야 하는 과정이다.

---

### 참고

**오존을 관측한 날짜는 연관이 없다?**

이 실습에서는 상식적으로 생각하여 연관이 없다고 진행하였지만, 실제로는 이러면 안된다. 상식선이 아니라 직접다 따져보고 영향을 끼치는지 끼치지 않는지 다 조사해봐야 하는 것이다.
