# 머신러닝, 딥러닝

## - Regularization

Logistic Regression을 위해 SKlearn에서 `LogisticRegression()`을 이용해왔다. 이는 우리가 알고 있는 알고리즘을 이용한 것이고, 다른 여러 알고리즘들이 있는데 그 여러 알고리즘을 포함한 범용적인 class를 제공한다. 우리가 알고 있던 알고리즘은 gradient descent방법인데 이 방법은 좋지만 학습속도가 느리다. 그래서 이름 포함한 여러 알고리즘이 있는 `SGDClassfier`에서 stochastic gradient descent algorithm 을 이용한다. 

위스콘틴 유방암 데이터셋을 가지고 SGDClassfier를 이용해 이진분류작업을 진행해보자.

```python
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier

model = SGDClassifier(loss='log',
                     max_iter=5000,
                     tol=1e-5,
                     random_state=2)
'''
loss의 기본값은 hinge이고 이 값을 이용하면 SVM방식으로 분류
만약 log를 주면 LogisticRegression방식으로 분류
반복학습을 진행하다보면 loss값이 산출되고 이 loss값은 계속 줄어야 한다.
이 줄어드는 loss값의 정도가 tol값보다 작아지면 학습을 멈춘다.
'''

cancer = load_breast_cancer()
x_data = cancer.data
t_data = cancer.target

train_x_data, valid_x_data, train_t_data, valid_t_data = \
train_test_split(x_data,
                 t_data,
                 stratify=t_data,
                 test_size=0.2,
                 random_state=2)

model.fit(train_x_data, train_t_data)

# 모델을 평가 비교

valid_acc = model.score(valid_x_data, valid_t_data)
print('train을 평가한 경우: {}'.format(valid_acc))
------------------------------------------------------------------------------
train을 평가한 경우: 0.9122807017543859
```

정규화도 해보고 진행해보자.

```python
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler
# 처음써보는 standard
# 정규화를 위해서 이상치 처리는 필수다.

model = SGDClassifier(loss='log',
                     max_iter=5000,
                     tol=1e-5,
                     random_state=2)

cancer = load_breast_cancer()
x_data = cancer.data
t_data = cancer.target

scaler = StandardScaler()
scaler.fit(x_data)


train_x_data, valid_x_data, train_t_data, valid_t_data = \
train_test_split(x_data,
                 t_data,
                 stratify=t_data,
                 test_size=0.2,
                 random_state=2)

model.fit(scaler.transform(train_x_data), train_t_data)
valid_acc = model.score(scaler.transform(valid_x_data), valid_t_data)
print('train을 평가한 경우: {}'.format(valid_acc))
------------------------------------------------------------------------------
train을 평가한 경우: 0.9649122807017544
```

그다음 정확도를 올리는 방법엔 뭐가 있을까?

과적합 문제가 있다. 과적합에는 과대적합과 과소적합이 있다. 일반적으로 과소적합은 많이 발생하지 않으며 보통 모델 자체의 문제이기에 크게 문제되지 않는다. 문제는 과대적합이다. 과대적합은 train데이터와 test데이터의 정확도차이가 큰 상황이며 <u>분산이 크다</u> 라고도 한다. 주요 원인으로는 '충분히 다양한 pattern의 데이터가 training data'에 포함되지 않는 경우이다. 

해결방법중에 데이터를 늘리는건 제한적이다. 데이터는 이미 주어진 부분이고, 그 데이터를 활용해야하는 것이기 때문이다. 그래서 또다른 방법으로는 모델의 복잡도를 줄이는 것이다.

현재까지는 입력데이터만큼 w의 개수를 사용한다. 이 w의 개수를 조절하는 것이다.  그 방법에는 2가지가 있다. 다음은 규제를 강화하는 방법이다.

- w자체의 값이 너무 커지지 않게 조절하는 방법
- w의 개수를 제한

이 둘다 데이터에 너무 밀적하게 함수가 그려지므로 데이터에 너무 가까워지지 않도록 하는 것이다.

과소적합은 거의 없지만 만약 생긴다면, 해결해야 한다. <u>편향이 크다</u>라고 하며 모델이 너무 불충분하게 만들어진 경우이다. 규제를 완화시켜주거나, 복잡도를 증가시켜야 한다.

![규제](./jpgfile/규제.png)

Regularization

- L1 규제: loss함수의 가중치에 절대값을 추가 ll w ll = sum(l wi l)를 구해서 cross Entropy식에서 규제 파라미터 a를 곱하여 더한다. a값을 크게하면 규제가 강해지고 a값이 작아지면 규제가 완화된다. SKlearn에서 L1 규제를 적용한 model을 우리에게 제공하며 이를 Lasso(라쏘)모델이라 한다. 근데 많이 사용되진 않는다. a값에 의해 규제정도가 너무 심하게 바뀌기 때문이다. 즉 조절하기가 어렵다.
- L2 규제: root(sum(wi^2))를 cross Entropy에 더한다. Ridge(릿지)모델이라 한다.

한번 L2규제를 적용하여 모델을 실행시켜보자.

```python
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler
# 처음써보는 standard
# 정규화를 위해서 이상치 처리는 필수다.

model = SGDClassifier(loss='log',
                     max_iter=5000,
                     tol=1e-5,
                     random_state=2,
                     penalty='L2',
                     alpha=0.001)

cancer = load_breast_cancer()
x_data = cancer.data
t_data = cancer.target

scaler = StandardScaler()
scaler.fit(x_data)


train_x_data, valid_x_data, train_t_data, valid_t_data = \
train_test_split(x_data,
                 t_data,
                 stratify=t_data,
                 test_size=0.2,
                 random_state=2)

model.fit(scaler.transform(train_x_data), train_t_data)
valid_acc = model.score(scaler.transform(valid_x_data), valid_t_data)
print('train을 평가한 경우: {}'.format(valid_acc))
------------------------------------------------------------------------------
train을 평가한 경우: 0.9649122807017544
```

ACC가 똑같이 나왔다. 이는 이전에도 오버피팅이 별로 발생하지 않음을 의미한다. ~~머쓱~~

