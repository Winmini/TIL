# 제 3고지 - 고차 미분 계산

### - 고차 미분



현재의 DeZero는 1차 미분을 자동으로 할 수 있지만, 그 이상은 할 수 없다. 이번에 2차 미분부터 n차 미분까지 자동으로 계산할 수 있도록 DeZero를 확장해보자. 그러기 위해서는 2차 이분을 계산하려는 현재의 역전파 구현을 근본적으로 재검토 해야한다.

검토를 위해 Variable 클래스를 살펴보자.

```python
class Variable:
    __array_priority__ = 200
    def __init__(self, data, name=None): # 이름의 기본 값은 None
        if data is not None:
            if not isinstance(data, np.ndarray):
                raise TypeError('{}은(는) 지원하지 않습니다.'. format(type(data)))
        
        self.data = data
        self.name = name # '이름' 추가
        self.grad = None
        self.creator = None
        self.generation = 0
    ...
```

Variable 클래스에서 self.data와 self.grad값에는 ndarray값이 들어간다. 이점을 감안하고, 

Function을 보자.

```python
class Function:
    def __call__(self, *inputs):
        inputs = [as_variable(x) for x in inputs]
        # 순전파 계산 부분
        xs = [x.data for x in inputs]
        ys = self.forward(*xs)
        if not isinstance(ys, tuple):
            ys = (ys,) 
        outputs = [Variable(as_array(y)) for y in ys]
        
        if Config.enable_backprop:
            self.generation = max([x.generation for x in inputs])
            # '연결'을 만듦
            for output in outputs:
                output.set_creator(self)
            self.inputs = inputs
            self.outputs = [weakref.ref(output) for output in outputs]
        
        return outputs if len(outputs) > 1 else outputs[0]
    ...
```

inputs으로 들어온 Variable의 data를 리스트로 만들어 xs에 넣은 후 forward를 통해 계산을 한다. 그리고 결과를 ys로 넘긴다.

밑은 결과와 입력값에 creator와 약한 참조를 통해 Variable과 Function의 관계, 즉 연결을 만든다.

예시를 통해서 살펴보자.

```python
class Sin(Function):
    def forward(self, x):
        y = np.sin(x)
        return y
    
    def backward(self, gy):
        x = self.inputs[0].data
        gx = gy * np.cos(x)
        return gx

def sin(x):
    return Sin()(x)

x = Variable(np.array(1.0))
y = sin(x)
```

밑의 함수를 실행시키고 아직 backward함수를 실행시키지 않은 경우 순전파의 계산이 이뤄지며 이렇게 계산하는 과정에서 변수와 함수의 '연결'이 만들어질 것이다. 그리고 x.data, forward, y,data값들에 ndarray란 값이 들어있는 상태이다.

이 상태로 역전파를 살펴보자.

```python
class Variable:
    ...
    
	def backward(self, retain_grad=False):
        if self.grad is None:
            self.grad = np.ones_like(self.data)
        
        funcs = []
        seen_set = set()
        def add_func(f):
            if f not in seen_set:
                seen_set.add(f)
                heapq.heappush(funcs, f)
        add_func(self.creator)
        while funcs:
            f = heapq.heappop(funcs)
            
            # 역전파 계산의 메인 처리부분
            gys = [output().grad for output in f.outputs]# 1
            gxs = f.backward(*gys)# 2
            if not isinstance(gxs, tuple):
                gxs = (gxs,)
            
            for x, gx in zip(f.inputs, gxs):# 3
                if x.grad is None:
                    x.grad = gx
                else:
                    x.grad = x.grad + gx
            # 여기까지
                
                if x.creator is not None:
                    add_func(x.creator)
                
            if not retain_grad:
                for y in f.outputs:
                    y().grad = None
```

1번을 보면 먼저 결과의 grad값을 리스트로 모은다. 그리고 grad는 ndarray값들을 참조하고 있다. 그리고 2번을 가면 backward에는 ndarray가 전달된다. 그리고 마지막 3번을 보면 출력쪽에서 전파하는 미분값을 함수의 입력변수의 grad로 설정한다. 만약 이것을 알고 다음 코드를 보자.

```python
x = Variable(np.array(1.0))
y = sin(x)
y.backward(retain_grad=True)
```

함수 계산(순전파)을 하고 바로 역전파를 진행시킨 코드이다. 이 역전파를 통해 모든 변수가 미분 결과를 메모리에 유지한다.

그럼 결과적으로, x와 y의 각각 Variable클래스에 data와 grad가 모두 ndarray로 차있는 상태이다. 이게 현재까지의 구현 방식이다.

주목할점 중 하나는 계산그래프의 '연결'이 만들어지는 시점이다. 순전파를 계산할 때 만들어지고, 역전파를 계산할 때에는 만들어지지 않는데, 여기서 문제가 발생한다.

역전파구현 부분을 보자.

```python
class Sin(Function):
    ...
    
    def backward(self, gy):
        x = self.inputs[0].data
        gx = gy * np.cos(x)
        return gx
```

여길보면 `gx = gy * np.cos(x)`라는 구체적인 계산이 이뤄지고 있음에도 아무런 계산그래프를 만들지 않는다. 만약 연결이 만들어진다면, 고차미분도 자동으로 수행할 수 있는데 말이다.

왜냐하면, gx가지금 sin의 미분형태가 들어간다. gx의 backward를 호출하면 x의 2차미분이 되는 것이다. 이런것을 염두에 두고 계산그래프를 어떻게 만드는지 생각해보자.

우리는 순전파 계산을 할 때 Variable인스턴스를 사용하여 계산을 하는 그 시점에서 연결이 만들어진다. backward에서도 Variable인스턴스를 통해 계산의 연결을 만들 수 있다. 그래서 미분값 grad를 ndarray를 넣는게 아니라 grad자체를 Variable로 만들고 그 Variable.data에 우리가 쓰던 ndarray데이터를 넣고 grad값은 Variable이 들어갈 '자리'가 있다고 생각하면 된다.

미분값을 나타내는 gy가 Variable 인스턴스가 되면 계산하면서 계산그래프가 '알아서' 만들어질 것이다. 이론은 이렇다. 이제 구현을 해보자.



먼저 Variable코드에서 중요한 한줄만 바꾸면 된다.

```python
class Variable:
    ...
    def backward(self, retain_grad=False):
        if self.grad is None:
            self.grad = Variable(np.ones_like(self.data)) # 여기만 Variable로
```

나머지는 수정할 필요가 없다. 뒤에 덧셈, 이런거 있지만 이미 다 연산자 오버로드를 마쳐놨기에 괜찮다. 다만 함수 클래스들의 역전파를 수정해주어야 한다. 왜 수정해주어야 하는지는 보면 안다.

Add는 괜찮지만 Mul 클래스를 보자. Add가 괜찮은 이유는 backward에서 계산하는 게 없다.

```python
class Mul(Function):
    ...
    def backward(self, gy):
#        x0, x1 = self.inputs[0].data, self.inputs[1].data
        x0, x1 = self.inputs
        return gy*x1, gy*x0
```

주석으로 차이를 보인다. 원래는 그 안의 데이터를 꺼냈지만, 이젠 꺼낼 필요 없이 그냥 Variable을 건네주면 된다. 곱셈도 역시 연산자 오버로드가 되어있어서 괜찮다. 나머지 Sub, Div, Pow 도 이에 맞게 수정하자.



하지만 기능을 달아놨다고 계속해서 계산하는 것은 효율적이지 않다. 만약 역전파를 한번 하고 나서 더 할 필요가 없다면, 이 역시 비활성으로 돌려주는것이 좋다. 따라서 backward에 옵션을 주자.

```python
class Variable:
    ...
    def backward(self, retain_grad=False, create_graph=False): # 여기 수정
        if self.grad is None:
            self.grad = Variable(np.ones_like(self.data))
        
        funcs = []
        seen_set = set()
        def add_func(f):
            if f not in seen_set:
                seen_set.add(f)
                heapq.heappush(funcs, f)
        add_func(self.creator)
        while funcs:
            f = heapq.heappop(funcs)
            gys = [output().grad for output in f.outputs]
            
            with using_config('enable_backprop', create_graph): # 여기 수정
                gxs = f.backward(*gys)
                if not isinstance(gxs, tuple):
                    gxs = (gxs,)

                for x, gx in zip(f.inputs, gxs):
                    if x.grad is None:
                        x.grad = gx
                    else:
                        x.grad = x.grad + gx

                    if x.creator is not None:
                        add_func(x.creator)

                if not retain_grad:
                    for y in f.outputs:
                        y().grad = None
```

기본값은 False로, 그리고 앞에서 사용했던 것처럼 with를 사용해주자.

프로그램의 흐름을 예를 들어 살펴보자. Mul() 클래스의 backward 메서드를 생각해보면 gy * x1계산을 할 때, *는 오버로드 되어있다. 따라서 Mul()(gy, x1) 이 호출되고, 이어서 부모 클래스의 Function의 `__call__` 함수가 호출된다. 그 메서드에서 Config.enable_backprop이 참조되고 모드가 전환된다. 기본값이 False인 것은 1회만 수행되는 경우가 훨씬 많기 때문이다.



예제를 통해 살펴보자.

앞서 다룬 $y = x^4 -2x^2$ 를 통해 2차 미분을 계산해보자. DeZero를 사용하면 다음과 같이 구현이 가능하다.

```python
def f(x):
    y = x ** 4 - 2 * x ** 2
    return y
    
x = Variable(np.array(2.0))
y = f(x)
y.backward(create_graph=True)
print(x.grad)
# 1차 미분
gx = x.grad
gx.backward()
print(x.grad)
# 2차 미분
```

실행 결과

```python
variable(24.0)
variable(68.0)
```

y.backward로 얻은 첫번째 역전파의 결과로 얻은 grad값으로 다시 역전파하면 2차미분의 결과를 얻을 수 있다. 그래서 얻은 결과는 24와 68, 하지만 실제로 계산해보면 1차미분은 24가 맞지만 2차미분은 44이다. 우리의 결과와 다르다. 근데 뭔가 잘 살펴보면 24 + 44로  68 나온듯 보인다. 이게 맞다. 왜냐하면 Variable에 미분 값이 남아 있으므로 우리의 코드를 생각해볼 때 grad가 존재하면 더하는 코드가 있었다. 그래서 그 부분에서 더해진 것이다. 따라서 새로운 계산을 하기 전에 Variable의 미분값을 '재설정' 해야한다.

```python
x = Variable(np.array(2.0))
y = f(x)
y.backward(create_graph=True)
print(x.grad)
# 1차 미분
gx = x.grad
x.cleargrad() # 초기화
gx.backward()
print(x.grad)
# 2차 미분
```

실행 결과

```python
variable(24.0)
variable(44.0)
```

잘 나오는 것을 볼 수 있다.



이제 뉴턴 방법을 활용해 최적화를 해볼 차례이다. 우선 뉴턴 방법을 활용한 최적화의 수식을 다시보자.

$x  \gets x-\frac {f'(x)}{f''(x)}$

1차 미분과 2차 미분을 사용하여 x를 갱신하고 있다. 이제 이것을 자동으로 수행되도록 해보자.

```python
x = Variable(np.array(2.0))
iters = 10

for i in range(iters):
    print(i, x)
    y = f(x)
    x.cleargrad()
    y.backward(create_graph=True)
    
    gx = x.grad
    x.cleargrad()
    gx.backward()
    gx2 = x.grad
    
    x.data -= gx.data / gx2.data
```

실행 결과

```python
0 variable(2.0)
1 variable(1.4545454545454546)
2 variable(1.1510467893775467)
3 variable(1.0253259289766978)
4 variable(1.0009084519430513)
5 variable(1.0000012353089454)
6 variable(1.000000000002289)
7 variable(1.0)
8 variable(1.0)
9 variable(1.0)
```

저번엔 2차 미분을 하드코딩 했지만, 이젠 자동으로 해준다. 그리고 7번만에 최솟값에 도달하는 것까지 확인할 수 있다.



sin 함수 고차미분도 이참에 해보자.

```python
class Sin(Function):
    def forward(self, x):
        y = np.sin(x)
        return y
    
    def backward(self, gy):
        x, = self.inputs
        gx = gy * cos(x)
        return gx

def sin(x):
    return Sin()(x)
```

근데 sin의 backward를 보면 cos가 쓰이고 있다. 그 말은 cos 클래스와 함수가 필요하다는 뜻이다. 참고로 backward 메서드 구현시 모든 계산은 반드시 DeZero 함수를 사용해야 한다. 만약 그에 해당하는 함수가 없다면 새로 구현해야 한다. 그래야 모든 계산이 원활하게 이뤄질 수 있다.

cos 클래스와 함수는 어렵지 않고 코드는 다음과 같다.

```python
class Cos(Function):
    def forward(self, x):
        y = np.cos(x)
        return y
    
    def backward(self, gy):
        x, = self.inputs
        gx = gy * -sin(x)
        return gx

def sin(x):
    return Sin()(x)
```

이젠는 사인함수도 고차 미분을 할 수 있다.



